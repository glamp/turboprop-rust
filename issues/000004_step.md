# Step 4: Embedding Model Integration

## Objective
Integrate embedding model to generate vector representations of code chunks.

## Tasks
1. Add fastembed-rs for embedding generation
2. Implement configurable embedding model support
3. Create embedding pipeline for text chunks
4. Add model download and caching functionality
5. Implement batch processing for efficiency
6. Add comprehensive tests with real embeddings

## Technical Approach
- Default model: sentence-transformers/all-MiniLM-L6-v2 (384 dimensions)
- Support for model configuration via CLI or config file
- Batch embedding generation for performance
- Model caching in `.turboprop/models/` directory
- Error handling for model download failures

## Dependencies to Add
- `fastembed` - Embedding model integration
- `reqwest` - HTTP client for model downloads
- `futures` - Async utilities

## Acceptance Criteria
- Downloads and caches embedding model on first run
- Generates 384-dimensional embeddings for text chunks
- Supports batch processing of multiple chunks
- Model is configurable via command line
- Handles network failures gracefully
- Embeddings are deterministic for same input
- Progress indicators during model download and embedding

## CLI Integration
```bash
tp index --repo . --model sentence-transformers/all-MiniLM-L6-v2
```

## Files Created/Modified
- `src/embeddings.rs` - Embedding generation logic
- `src/models.rs` - Model management and caching
- `src/config.rs` - Configuration handling
- `tests/embedding_tests.rs` - Embedding generation tests

## Test Cases
- Test embedding generation with default model
- Test batch embedding processing
- Test model caching functionality
- Test embedding consistency
- Verify embedding dimensions match model specs