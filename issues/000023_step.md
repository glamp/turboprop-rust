# Step 23: Update CLI for New Model Selection and Configuration

## Objective
Update the command-line interface to support selection and configuration of the new embedding models, including model-specific options and improved help documentation.

## Background
With the addition of GGUF and Qwen3 models, users need to be able to:
- Select from available embedding models
- Configure model-specific options (like instructions for Qwen3)
- Understand model capabilities and requirements
- Handle model-specific download and setup

## Tasks
1. Update CLI arguments to support model selection
2. Add model-specific configuration options
3. Enhance help documentation with model information
4. Add model listing functionality
5. Update configuration file support for new models
6. Add validation for model compatibility and requirements
7. Improve error messages for model-related issues

## Implementation Details

### Current CLI Analysis
Looking at `src/cli.rs` and `src/commands/`, the current model selection is limited and hardcoded to fastembed defaults.

### 1. Enhanced Model Selection
Update CLI arguments in `src/cli.rs`:
```rust
#[derive(Parser)]
#[command(name = "tp")]
#[command(about = "TurboProp - Semantic code search and indexing")]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
    
    /// Embedding model to use
    #[arg(long, value_name = "MODEL")]
    pub model: Option<String>,
    
    /// List available embedding models
    #[arg(long)]
    pub list_models: bool,
    
    /// Model-specific instruction (for Qwen3 models)
    #[arg(long, value_name = "INSTRUCTION")]
    pub instruction: Option<String>,
    
    /// Force model download even if cached
    #[arg(long)]
    pub force_download: bool,
}

#[derive(Subcommand)]
pub enum Commands {
    /// Build or update the search index
    Index {
        /// Repository path to index
        #[arg(short, long, value_name = "PATH")]
        repo: PathBuf,
        
        /// Embedding model to use (overrides global setting)
        #[arg(long, value_name = "MODEL")]
        model: Option<String>,
        
        /// Model instruction for context-aware embeddings
        #[arg(long, value_name = "INSTRUCTION")]
        instruction: Option<String>,
        
        // ... existing arguments
    },
    
    /// Search the indexed repository
    Search {
        /// Search query
        query: String,
        
        /// Embedding model to use (overrides global setting)  
        #[arg(long, value_name = "MODEL")]
        model: Option<String>,
        
        /// Model instruction for query embeddings
        #[arg(long, value_name = "INSTRUCTION")]  
        instruction: Option<String>,
        
        // ... existing arguments
    },
    
    /// Model management commands
    Model {
        #[command(subcommand)]
        action: ModelCommands,
    },
}

#[derive(Subcommand)]
pub enum ModelCommands {
    /// List available models
    List,
    /// Download a specific model
    Download {
        /// Model name to download
        model: String,
    },
    /// Show model information
    Info {
        /// Model name
        model: String,
    },
    /// Clear model cache
    Clear {
        /// Specific model to clear (optional)
        model: Option<String>,
    },
}
```

### 2. Model Information and Listing
Add model management commands in `src/commands/mod.rs`:
```rust
pub mod model;
```

Create `src/commands/model.rs`:
```rust
use anyhow::Result;
use clap::Args;
use tracing::{info, warn};

use crate::models::{ModelManager, ModelInfo};
use crate::cli::ModelCommands;

pub async fn handle_model_command(cmd: ModelCommands) -> Result<()> {
    match cmd {
        ModelCommands::List => list_models().await,
        ModelCommands::Download { model } => download_model(&model).await,
        ModelCommands::Info { model } => show_model_info(&model).await,
        ModelCommands::Clear { model } => clear_model_cache(model.as_deref()).await,
    }
}

async fn list_models() -> Result<()> {
    let models = ModelManager::get_available_models();
    let manager = ModelManager::default();
    
    println!("Available Embedding Models:\n");
    
    for model in models {
        let cached = manager.is_model_cached(&model.name);
        let cache_status = if cached { "âœ“ cached" } else { "  download required" };
        
        println!("  {} [{}]", model.name, cache_status);
        println!("    Description: {}", model.description);
        println!("    Type: {:?}, Backend: {:?}", model.model_type, model.backend);
        println!("    Dimensions: {}, Size: {}", 
                 model.dimensions, 
                 format_size(model.size_bytes));
        
        if let Some(url) = &model.download_url {
            println!("    Download URL: {}", url);
        }
        
        println!();
    }
    
    Ok(())
}

async fn download_model(model_name: &str) -> Result<()> {
    let models = ModelManager::get_available_models();
    let model_info = models.iter()
        .find(|m| m.name == model_name)
        .ok_or_else(|| anyhow::anyhow!("Model '{}' not found", model_name))?;
    
    let manager = ModelManager::default();
    
    match model_info.backend {
        crate::models::ModelBackend::FastEmbed => {
            info!("FastEmbed models are downloaded automatically on first use");
        },
        crate::models::ModelBackend::Candle => {
            info!("Downloading GGUF model: {}", model_name);
            let _path = manager.download_gguf_model(model_info).await?;
            info!("Successfully downloaded GGUF model");
        },
        crate::models::ModelBackend::Custom => {
            info!("Downloading Hugging Face model: {}", model_name);
            let _path = manager.download_huggingface_model(&model_info.name).await?;
            info!("Successfully downloaded Hugging Face model");
        },
    }
    
    Ok(())
}

async fn show_model_info(model_name: &str) -> Result<()> {
    let models = ModelManager::get_available_models();
    let model_info = models.iter()
        .find(|m| m.name == model_name)
        .ok_or_else(|| anyhow::anyhow!("Model '{}' not found", model_name))?;
    
    println!("Model Information: {}\n", model_info.name);
    println!("Description: {}", model_info.description);
    println!("Type: {:?}", model_info.model_type);
    println!("Backend: {:?}", model_info.backend);
    println!("Dimensions: {}", model_info.dimensions);
    println!("Size: {}", format_size(model_info.size_bytes));
    
    if let Some(url) = &model_info.download_url {
        println!("Download URL: {}", url);
    }
    
    let manager = ModelManager::default();
    let cached = manager.is_model_cached(&model_info.name);
    println!("Cache Status: {}", if cached { "Cached locally" } else { "Not cached" });
    
    // Model-specific information
    match model_info.name.as_str() {
        name if name.contains("qwen3") => {
            println!("\nQwen3 Model Features:");
            println!("- Supports instruction-based embeddings with --instruction flag");
            println!("- Multilingual support (100+ languages)");
            println!("- Optimized for code and text retrieval");
        },
        name if name.contains("nomic-embed-code") => {
            println!("\nNomic Embed Code Features:");
            println!("- Specialized for code search and retrieval");
            println!("- Supports multiple programming languages");
            println!("- GGUF quantized for efficient inference");
        },
        _ => {}
    }
    
    Ok(())
}

async fn clear_model_cache(model_name: Option<&str>) -> Result<()> {
    let manager = ModelManager::default();
    
    match model_name {
        Some(name) => {
            info!("Clearing cache for model: {}", name);
            manager.remove_model(name)?;
        },
        None => {
            warn!("Clearing all model caches");
            manager.clear_cache()?;
        }
    }
    
    info!("Model cache cleared successfully");
    Ok(())
}

fn format_size(bytes: u64) -> String {
    const UNITS: &[&str] = &["B", "KB", "MB", "GB"];
    let mut size = bytes as f64;
    let mut unit_index = 0;
    
    while size >= 1024.0 && unit_index < UNITS.len() - 1 {
        size /= 1024.0;
        unit_index += 1;
    }
    
    format!("{:.1} {}", size, UNITS[unit_index])
}
```

### 3. Enhanced Help Documentation
Update help text in CLI commands:
```rust
/// Build or update the search index
Index {
    #[arg(long, value_name = "MODEL", help = r#"Embedding model to use. Available options:
    - sentence-transformers/all-MiniLM-L6-v2 (default, fast)
    - sentence-transformers/all-MiniLM-L12-v2 (better accuracy)
    - nomic-embed-code.Q5_K_S.gguf (specialized for code)
    - Qwen/Qwen3-Embedding-0.6B (multilingual, instruction-capable)
Use 'tp model list' to see all available models"#)]
    model: Option<String>,
    
    #[arg(long, value_name = "INSTRUCTION", help = r#"Instruction for context-aware embeddings (Qwen3 only).
Examples:
    --instruction "Represent this code for search"
    --instruction "Encode this text for similarity search""#)]
    instruction: Option<String>,
}
```

### 4. Configuration File Updates
Update `src/config.rs` to support new model options:
```rust
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct TurboPropConfig {
    // ... existing fields
    
    /// Default embedding model to use
    pub default_model: Option<String>,
    
    /// Model-specific configurations
    pub models: Option<std::collections::HashMap<String, ModelConfig>>,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ModelConfig {
    /// Custom instruction for this model
    pub instruction: Option<String>,
    
    /// Model-specific cache directory
    pub cache_dir: Option<PathBuf>,
    
    /// Custom download URL override
    pub download_url: Option<String>,
}

impl Default for TurboPropConfig {
    fn default() -> Self {
        Self {
            // ... existing defaults
            default_model: Some("sentence-transformers/all-MiniLM-L6-v2".to_string()),
            models: None,
        }
    }
}
```

### 5. Model Validation and Error Handling
Add model validation in `src/commands/index.rs` and `src/commands/search.rs`:
```rust
pub async fn validate_model_selection(model_name: &str) -> Result<ModelInfo> {
    let available_models = ModelManager::get_available_models();
    
    let model_info = available_models.iter()
        .find(|m| m.name == model_name)
        .ok_or_else(|| anyhow::anyhow!(
            "Model '{}' is not available. Use 'tp model list' to see available models.",
            model_name
        ))?;
    
    // Check if model requires download
    let manager = ModelManager::default();
    if !manager.is_model_cached(&model_info.name) {
        match model_info.backend {
            ModelBackend::FastEmbed => {
                info!("Model will be downloaded automatically on first use");
            },
            _ => {
                return Err(anyhow::anyhow!(
                    "Model '{}' is not cached. Download it first with: tp model download {}",
                    model_name, model_name
                ));
            }
        }
    }
    
    Ok(model_info.clone())
}
```

## Files to Create/Modify
- `src/cli.rs` - Update CLI arguments and help text
- `src/commands/mod.rs` - Add model command module
- `src/commands/model.rs` - New model management commands
- `src/commands/index.rs` - Add model selection and validation
- `src/commands/search.rs` - Add model selection and validation  
- `src/config.rs` - Add model configuration support
- `src/main.rs` - Wire up new model commands

## Acceptance Criteria
- [ ] Users can list available models with descriptions
- [ ] Users can select models for indexing and searching
- [ ] Model-specific options (instructions) are supported
- [ ] Help text clearly explains model options and usage
- [ ] Configuration file supports model preferences
- [ ] Error messages guide users to correct model usage
- [ ] Model validation prevents invalid selections
- [ ] Model download is handled gracefully

## Success Validation
```bash
# List all available models
tp model list

# Show specific model information
tp model info "Qwen/Qwen3-Embedding-0.6B"

# Download a model
tp model download "nomic-embed-code.Q5_K_S.gguf"

# Use different models for indexing
tp index --repo . --model "Qwen/Qwen3-Embedding-0.6B" --instruction "Represent this code for search"

# Use different models for searching
tp search "jwt authentication" --model "nomic-embed-code.Q5_K_S.gguf"

# Test help text
tp --help
tp index --help
tp search --help
```

## Notes
- Model selection should be intuitive and well-documented
- Error messages should guide users to correct actions
- Large model downloads should show progress
- Configuration should support both CLI and file-based preferences
- Backward compatibility with existing usage patterns should be maintained