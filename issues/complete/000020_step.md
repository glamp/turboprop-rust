# Step 20: Extend Model Architecture for Multiple Model Types

## Objective
Extend the current model architecture to support different embedding model types beyond sentence-transformers, including GGUF and custom Hugging Face models.

## Background
Current architecture assumes all models use fastembed's `TextEmbedding` interface. The new models require different loading and inference mechanisms:
- GGUF models need custom loaders (candle or similar)
- Some Hugging Face models may not be supported by fastembed yet

## Tasks
1. Define model type enumeration for different embedding backends
2. Create trait abstractions for different model implementations
3. Extend `ModelInfo` to include model type and backend information
4. Update model manager to handle multiple model types
5. Add model type detection and validation
6. Prepare interfaces for different embedding implementations

## Implementation Details

### Current Architecture Analysis
Looking at `src/models.rs:82-97`, current models are hardcoded:
```rust
pub fn get_available_models() -> Vec<ModelInfo> {
    vec![
        ModelInfo::new(
            "sentence-transformers/all-MiniLM-L6-v2".to_string(),
            "Fast and lightweight model, good for general use".to_string(),
            384,
            23_000_000,
        ),
        // Only sentence-transformer models...
    ]
}
```

### New Architecture Design

#### 1. Model Type Enumeration
Add to `src/types.rs` or `src/models.rs`:
```rust
#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub enum ModelType {
    SentenceTransformer,
    GGUF,
    HuggingFace,
}

#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub enum ModelBackend {
    FastEmbed,
    Candle,
    Custom,
}
```

#### 2. Enhanced ModelInfo Structure
Extend `ModelInfo` at `src/models.rs:12-21`:
```rust
#[derive(Debug, Clone)]
pub struct ModelInfo {
    pub name: String,
    pub description: String,
    pub dimensions: usize,
    pub size_bytes: u64,
    pub model_type: ModelType,        // NEW
    pub backend: ModelBackend,        // NEW
    pub download_url: Option<String>, // NEW for direct downloads
    pub local_path: Option<PathBuf>,  // NEW for local models
}
```

#### 3. Embedding Backend Trait
Create trait for different embedding implementations:
```rust
pub trait EmbeddingBackend: Send + Sync {
    fn load_model(&self, model_info: &ModelInfo) -> Result<Box<dyn EmbeddingModel>>;
    fn supports_model(&self, model_type: &ModelType) -> bool;
}

pub trait EmbeddingModel: Send + Sync {
    fn embed(&self, texts: &[String]) -> Result<Vec<Vec<f32>>>;
    fn dimensions(&self) -> usize;
    fn max_sequence_length(&self) -> usize;
}
```

#### 4. Update Available Models List
Replace hardcoded models with comprehensive list:
```rust
pub fn get_available_models() -> Vec<ModelInfo> {
    vec![
        // Existing sentence-transformer models
        ModelInfo::new(
            "sentence-transformers/all-MiniLM-L6-v2",
            "Fast and lightweight model, good for general use",
            384,
            23_000_000,
            ModelType::SentenceTransformer,
            ModelBackend::FastEmbed,
            None,
            None,
        ),
        // New GGUF model
        ModelInfo::new(
            "nomic-embed-code.Q5_K_S.gguf",
            "Nomic code embedding model optimized for code search",
            768, // Check actual dimensions
            2_500_000_000, // ~2.5GB estimated
            ModelType::GGUF,
            ModelBackend::Candle,
            Some("https://huggingface.co/nomic-ai/nomic-embed-code-GGUF/resolve/main/nomic-embed-code.Q5_K_S.gguf".to_string()),
            None,
        ),
        // New Qwen model
        ModelInfo::new(
            "Qwen/Qwen3-Embedding-0.6B",
            "Qwen3 embedding model for multilingual and code retrieval",
            1024, // Check actual dimensions
            600_000_000, // ~600MB
            ModelType::HuggingFace,
            ModelBackend::Custom,
            None,
            None,
        ),
    ]
}
```

## Files to Create/Modify
- `src/models.rs` - Extend ModelInfo and add model type support
- `src/types.rs` - Add ModelType and ModelBackend enums if needed
- `src/embeddings.rs` - Prepare for trait-based embedding interface

## Acceptance Criteria
- [ ] ModelInfo includes model type and backend information
- [ ] Model type enumeration covers all required model types
- [ ] Available models list includes the two new required models
- [ ] Trait design supports different embedding backends
- [ ] Model manager can differentiate between model types
- [ ] No breaking changes to existing fastembed model support
- [ ] All existing tests pass

## Success Validation
```bash
# Verify compilation
cargo check

# Run existing tests
cargo test

# Verify model info updates
cargo run --bin tp -- --help | grep -A 10 model
```

## Notes
This step focuses on the architectural foundation. Actual model loading implementations will be added in subsequent steps. The goal is to create a clean abstraction that can support multiple embedding backends without breaking existing functionality.

## Proposed Solution

I have successfully implemented the multi-model architecture extension with the following changes:

### 1. Added Model Type and Backend Enums (`src/types.rs`)
- Added `ModelType` enum: `SentenceTransformer`, `GGUF`, `HuggingFace`
- Added `ModelBackend` enum: `FastEmbed`, `Candle`, `Custom`
- Both enums are serializable and support all required model types

### 2. Extended ModelInfo Structure (`src/models.rs`)
- Added `model_type: ModelType` field to classify model types
- Added `backend: ModelBackend` field to specify which backend loads the model
- Added `download_url: Option<String>` for direct model downloads
- Added `local_path: Option<PathBuf>` for locally stored models
- Updated constructor to accept all new parameters

### 3. Created Embedding Backend Traits (`src/models.rs`)
- Implemented `EmbeddingBackend` trait with:
  - `load_model(&self, model_info: &ModelInfo) -> Result<Box<dyn EmbeddingModel>>`
  - `supports_model(&self, model_type: &ModelType) -> bool`
- Implemented `EmbeddingModel` trait with:
  - `embed(&self, texts: &[String]) -> Result<Vec<Vec<f32>>>`
  - `dimensions(&self) -> usize`
  - `max_sequence_length(&self) -> usize`

### 4. Updated Available Models List
- Updated existing sentence-transformer models with new fields
- Added Nomic GGUF model: `nomic-embed-code.Q5_K_S.gguf` (768 dims, Candle backend)
- Added Qwen model: `Qwen/Qwen3-Embedding-0.6B` (1024 dims, Custom backend)
- All models properly categorized by type and backend

### 5. Validation Results
✅ All 182 unit tests pass
✅ Code compiles successfully with `cargo check`
✅ No breaking changes to existing functionality
✅ Backward compatibility maintained for existing fastembed models

The architecture now supports the required multi-model functionality while maintaining clean abstractions for future backend implementations.