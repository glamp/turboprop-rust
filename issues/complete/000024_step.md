# Step 24: Comprehensive Testing for New Model Support

## Objective
Create comprehensive test coverage for the new embedding model support, including unit tests, integration tests, and end-to-end validation of GGUF and Qwen3 model functionality.

## Background
With the addition of multiple model backends (FastEmbed, GGUF, Hugging Face), comprehensive testing is essential to ensure:
- Model loading and caching work correctly
- Embedding generation produces valid results
- CLI integration functions properly
- Error handling provides useful feedback
- Performance meets expectations

## Tasks
1. Create unit tests for new model backends
2. Add integration tests for model loading and caching
3. Create end-to-end tests for CLI model commands
4. Add performance benchmarks for new models
5. Create regression tests to ensure compatibility
6. Add error scenario testing
7. Validate model-specific features (instructions, etc.)

## Implementation Details

### 1. Unit Tests for Model Backends

#### Test GGUF Backend
Create `tests/gguf_backend_tests.rs`:
```rust
use anyhow::Result;
use tempfile::TempDir;
use turboprop::backends::gguf::{GGUFBackend, GGUFEmbeddingModel};
use turboprop::models::{ModelInfo, ModelType, ModelBackend};

#[tokio::test]
async fn test_gguf_backend_creation() -> Result<()> {
    let backend = GGUFBackend::new()?;
    assert!(backend.device.is_cpu()); // Initially CPU only
    Ok(())
}

#[tokio::test]
#[ignore] // Requires large model download
async fn test_gguf_model_download_and_load() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let model_info = ModelInfo::new(
        "nomic-embed-code.Q5_K_S.gguf",
        "Test GGUF model",
        768,
        2_500_000_000,
        ModelType::GGUF,
        ModelBackend::Candle,
        Some("https://huggingface.co/nomic-ai/nomic-embed-code-GGUF/resolve/main/nomic-embed-code.Q5_K_S.gguf".to_string()),
        None,
    );
    
    let manager = turboprop::models::ModelManager::new(temp_dir.path());
    let model_path = manager.download_gguf_model(&model_info).await?;
    
    assert!(model_path.exists());
    assert!(model_path.is_file());
    
    let backend = GGUFBackend::new()?;
    let _model = backend.load_model(&model_path)?;
    
    Ok(())
}

#[tokio::test]
async fn test_gguf_embedding_generation() -> Result<()> {
    // This test would use a small test GGUF model or mock
    // Full implementation depends on test data availability
    let test_texts = vec![
        "function calculateSum(a, b) { return a + b; }".to_string(),
        "def process_data(data): return data.strip()".to_string(),
    ];
    
    // Mock or use small test model
    // let model = create_test_gguf_model()?;
    // let embeddings = model.embed(&test_texts)?;
    
    // assert_eq!(embeddings.len(), 2);
    // assert_eq!(embeddings[0].len(), 768); // Expected dimensions
    
    Ok(())
}
```

#### Test Qwen3 Backend
Create `tests/qwen3_backend_tests.rs`:
```rust
use anyhow::Result;
use turboprop::backends::huggingface::{HuggingFaceBackend, Qwen3EmbeddingModel};
use turboprop::models::{ModelInfo, ModelType, ModelBackend};

#[tokio::test]
async fn test_huggingface_backend_creation() -> Result<()> {
    let backend = HuggingFaceBackend::new()?;
    assert!(backend.api.is_ok()); // API client created successfully
    Ok(())
}

#[tokio::test]
#[ignore] // Requires model download
async fn test_qwen3_model_download_and_load() -> Result<()> {
    let backend = HuggingFaceBackend::new()?;
    let _model = backend.load_qwen3_model("Qwen/Qwen3-Embedding-0.6B").await?;
    Ok(())
}

#[tokio::test]
async fn test_qwen3_instruction_embeddings() -> Result<()> {
    // Test instruction-based embedding generation
    let test_texts = vec![
        "This is a code function for testing".to_string(),
        "另一个测试文本".to_string(), // Chinese text
    ];
    
    let instruction = "Represent this text for similarity search";
    
    // Mock or use test model
    // let model = create_test_qwen3_model()?;
    // let embeddings = model.embed_with_instruction(&test_texts, Some(instruction))?;
    
    // assert_eq!(embeddings.len(), 2);
    // assert_eq!(embeddings[0].len(), 1024); // Expected dimensions
    
    Ok(())
}

#[tokio::test]
async fn test_qwen3_multilingual_support() -> Result<()> {
    let multilingual_texts = vec![
        "Hello world".to_string(),
        "你好世界".to_string(), // Chinese
        "Hola mundo".to_string(), // Spanish
        "console.log('test')".to_string(), // JavaScript code
    ];
    
    // Test that model can handle multilingual input
    // Implementation depends on model availability
    Ok(())
}
```

### 2. Integration Tests for Model Management

Create `tests/model_integration_tests.rs`:
```rust
use anyhow::Result;
use tempfile::TempDir;
use turboprop::models::{ModelManager, ModelInfo};
use turboprop::embeddings::{EmbeddingGenerator, EmbeddingOptions};

#[tokio::test]
async fn test_model_manager_caching() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let manager = ModelManager::new(temp_dir.path());
    
    // Test fastembed model (should be cached after first use)
    let model_name = "sentence-transformers/all-MiniLM-L6-v2";
    assert!(!manager.is_model_cached(model_name));
    
    // After creating embedding generator, model should be cached
    let models = ModelManager::get_available_models();
    let model_info = models.iter()
        .find(|m| m.name == model_name)
        .unwrap();
    
    let _generator = EmbeddingGenerator::new_with_model(model_info).await?;
    // Note: FastEmbed caching behavior may differ
    
    Ok(())
}

#[tokio::test]
async fn test_embedding_generation_consistency() -> Result<()> {
    let test_text = vec!["function test() { return 42; }".to_string()];
    
    // Test that same text produces consistent embeddings
    let models = ModelManager::get_available_models();
    
    for model_info in models.iter().take(1) { // Test first available model
        let generator = EmbeddingGenerator::new_with_model(model_info).await?;
        
        let embeddings1 = generator.embed(&test_text)?;
        let embeddings2 = generator.embed(&test_text)?;
        
        assert_eq!(embeddings1.len(), embeddings2.len());
        assert_eq!(embeddings1[0].len(), embeddings2[0].len());
        
        // Embeddings should be identical (or very close)
        let cosine_sim = cosine_similarity(&embeddings1[0], &embeddings2[0]);
        assert!(cosine_sim > 0.99, "Embeddings should be consistent");
    }
    
    Ok(())
}

#[tokio::test]
async fn test_model_switching() -> Result<()> {
    let test_texts = vec![
        "function calculateTotal(items) { return items.reduce((sum, item) => sum + item.price, 0); }".to_string(),
    ];
    
    let models = ModelManager::get_available_models();
    let mut embeddings_by_model = std::collections::HashMap::new();
    
    // Generate embeddings with different models
    for model_info in models.iter().take(2) { // Test first two models
        if let Ok(generator) = EmbeddingGenerator::new_with_model(model_info).await {
            if let Ok(embeddings) = generator.embed(&test_texts) {
                embeddings_by_model.insert(model_info.name.clone(), embeddings);
            }
        }
    }
    
    // Different models should produce different embeddings
    if embeddings_by_model.len() >= 2 {
        let model_names: Vec<_> = embeddings_by_model.keys().collect();
        let emb1 = &embeddings_by_model[model_names[0]][0];
        let emb2 = &embeddings_by_model[model_names[1]][0];
        
        let similarity = cosine_similarity(emb1, emb2);
        assert!(similarity < 0.95, "Different models should produce different embeddings");
    }
    
    Ok(())
}

fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    dot_product / (norm_a * norm_b)
}
```

### 3. CLI Integration Tests

Create `tests/cli_model_tests.rs`:
```rust
use anyhow::Result;
use assert_cmd::Command;
use predicates::prelude::*;
use tempfile::TempDir;

#[tokio::test]
async fn test_model_list_command() -> Result<()> {
    let mut cmd = Command::cargo_bin("tp")?;
    cmd.arg("model").arg("list");
    
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("Available Embedding Models"))
        .stdout(predicate::str::contains("sentence-transformers/all-MiniLM-L6-v2"))
        .stdout(predicate::str::contains("nomic-embed-code.Q5_K_S.gguf"))
        .stdout(predicate::str::contains("Qwen/Qwen3-Embedding-0.6B"));
    
    Ok(())
}

#[tokio::test]
async fn test_model_info_command() -> Result<()> {
    let mut cmd = Command::cargo_bin("tp")?;
    cmd.arg("model")
        .arg("info")
        .arg("sentence-transformers/all-MiniLM-L6-v2");
    
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("Model Information"))
        .stdout(predicate::str::contains("Dimensions: 384"))
        .stdout(predicate::str::contains("FastEmbed"));
    
    Ok(())
}

#[tokio::test]
async fn test_index_with_custom_model() -> Result<()> {
    let temp_dir = TempDir::new()?;
    
    // Create a small test repository
    std::fs::write(
        temp_dir.path().join("test.js"),
        "function hello() { console.log('world'); }"
    )?;
    
    let mut cmd = Command::cargo_bin("tp")?;
    cmd.arg("index")
        .arg("--repo").arg(temp_dir.path())
        .arg("--model").arg("sentence-transformers/all-MiniLM-L6-v2")
        .arg("--limit").arg("1");
    
    cmd.assert().success();
    
    Ok(())
}

#[tokio::test]
async fn test_search_with_custom_model() -> Result<()> {
    let temp_dir = TempDir::new()?;
    
    // Create and index a test repository first
    std::fs::write(
        temp_dir.path().join("test.py"),
        "def authenticate_user(username, password): return True"
    )?;
    
    // Index first
    let mut index_cmd = Command::cargo_bin("tp")?;
    index_cmd.arg("index")
        .arg("--repo").arg(temp_dir.path())
        .arg("--model").arg("sentence-transformers/all-MiniLM-L6-v2");
    index_cmd.assert().success();
    
    // Then search
    let mut search_cmd = Command::cargo_bin("tp")?;
    search_cmd.arg("search")
        .arg("authentication")
        .arg("--repo").arg(temp_dir.path())
        .arg("--model").arg("sentence-transformers/all-MiniLM-L6-v2");
    
    search_cmd.assert()
        .success()
        .stdout(predicate::str::contains("authenticate_user"));
    
    Ok(())
}

#[tokio::test]
async fn test_qwen3_instruction_cli() -> Result<()> {
    let temp_dir = TempDir::new()?;
    
    std::fs::write(
        temp_dir.path().join("code.rs"),
        "fn main() { println!(\"Hello, world!\"); }"
    )?;
    
    let mut cmd = Command::cargo_bin("tp")?;
    cmd.arg("index")
        .arg("--repo").arg(temp_dir.path())
        .arg("--model").arg("Qwen/Qwen3-Embedding-0.6B")
        .arg("--instruction").arg("Represent this code for search");
    
    // This test may be ignored if Qwen3 model is not available
    // cmd.assert().success();
    
    Ok(())
}
```

### 4. Performance Benchmarks

Create `benches/model_performance.rs`:
```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use turboprop::models::ModelManager;
use turboprop::embeddings::EmbeddingGenerator;
use tokio::runtime::Runtime;

fn benchmark_model_loading(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let models = ModelManager::get_available_models();
    
    c.bench_function("load_fastembed_model", |b| {
        b.iter(|| {
            let model_info = &models[0]; // First model (sentence-transformer)
            rt.block_on(async {
                let _generator = EmbeddingGenerator::new_with_model(black_box(model_info)).await.unwrap();
            })
        })
    });
}

fn benchmark_embedding_generation(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let models = ModelManager::get_available_models();
    
    let test_texts = vec![
        "function calculateSum(a, b) { return a + b; }".to_string(),
        "def process_data(data): return data.strip().upper()".to_string(),
        "class UserService { authenticate(user) { return true; } }".to_string(),
    ];
    
    for model_info in models.iter().take(2) {
        let generator = rt.block_on(async {
            EmbeddingGenerator::new_with_model(model_info).await.unwrap()
        });
        
        let bench_name = format!("embed_{}", model_info.name.replace('/', "_"));
        c.bench_function(&bench_name, |b| {
            b.iter(|| {
                generator.embed(black_box(&test_texts)).unwrap()
            })
        });
    }
}

fn benchmark_model_comparison(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let models = ModelManager::get_available_models();
    
    let code_text = vec![
        "async function fetchUserData(userId) { 
            const response = await fetch(`/api/users/${userId}`);
            return response.json();
        }".to_string(),
    ];
    
    let mut group = c.benchmark_group("model_comparison");
    
    for model_info in models.iter().take(3) {
        if let Ok(generator) = rt.block_on(EmbeddingGenerator::new_with_model(model_info)) {
            group.bench_with_input(
                criterion::BenchmarkId::new("embed", &model_info.name),
                &code_text,
                |b, texts| {
                    b.iter(|| generator.embed(black_box(texts)).unwrap())
                },
            );
        }
    }
    
    group.finish();
}

criterion_group!(
    benches,
    benchmark_model_loading,
    benchmark_embedding_generation,
    benchmark_model_comparison
);
criterion_main!(benches);
```

### 5. Error Scenario Testing

Create `tests/model_error_tests.rs`:
```rust
use anyhow::Result;
use turboprop::models::ModelManager;
use turboprop::embeddings::EmbeddingGenerator;

#[tokio::test]
async fn test_invalid_model_selection() -> Result<()> {
    let models = ModelManager::get_available_models();
    
    // Try to create generator with non-existent model
    let fake_model = turboprop::models::ModelInfo::new(
        "nonexistent/model",
        "Fake model",
        512,
        1000,
        turboprop::models::ModelType::SentenceTransformer,
        turboprop::models::ModelBackend::FastEmbed,
        None,
        None,
    );
    
    let result = EmbeddingGenerator::new_with_model(&fake_model).await;
    assert!(result.is_err());
    
    Ok(())
}

#[tokio::test]
async fn test_corrupted_cache_handling() -> Result<()> {
    // Create corrupted cache directory and test recovery
    let temp_dir = tempfile::TempDir::new()?;
    let manager = ModelManager::new(temp_dir.path());
    
    // Create fake cache directory with invalid contents
    let fake_model_path = manager.get_model_path("sentence-transformers/all-MiniLM-L6-v2");
    std::fs::create_dir_all(&fake_model_path)?;
    std::fs::write(fake_model_path.join("invalid_file"), "corrupted")?;
    
    // Model should not be considered cached with invalid contents
    assert!(!manager.is_model_cached("sentence-transformers/all-MiniLM-L6-v2"));
    
    Ok(())
}

#[tokio::test]
async fn test_network_failure_handling() -> Result<()> {
    // Test graceful handling of network failures during model download
    // This would require mocking network requests or using offline mode
    Ok(())
}
```

## Files to Create/Modify
- `tests/gguf_backend_tests.rs` - GGUF backend unit tests
- `tests/qwen3_backend_tests.rs` - Qwen3 backend unit tests
- `tests/model_integration_tests.rs` - Integration tests
- `tests/cli_model_tests.rs` - CLI integration tests
- `tests/model_error_tests.rs` - Error scenario tests
- `benches/model_performance.rs` - Performance benchmarks
- `tests/common.rs` - Shared test utilities

## Acceptance Criteria
- [ ] All model backends have comprehensive unit tests
- [ ] Integration tests cover model loading and caching
- [ ] CLI commands are tested end-to-end
- [ ] Performance benchmarks establish baselines
- [ ] Error scenarios are handled gracefully
- [ ] Test coverage > 90% for new model functionality
- [ ] Tests run in reasonable time
- [ ] Both online and offline test scenarios work

## Success Validation
```bash
# Run all tests
cargo test

# Run model-specific tests
cargo test model

# Run performance benchmarks
cargo bench

# Test coverage
cargo tarpaulin --out Html

# Integration tests with actual models (may require downloads)
cargo test -- --ignored
```

## Proposed Solution

I will implement comprehensive testing for the new model support by following a test-driven development approach:

1. **Analyze Existing Codebase**: First, examine the current model management infrastructure, embedding generation code, and CLI interfaces to understand what components need testing.

2. **Create Unit Tests**: Implement focused unit tests for each model backend (GGUF, Qwen3/HuggingFace) that test core functionality without external dependencies.

3. **Build Integration Tests**: Create tests that validate model loading, caching, and embedding generation across different backends with proper isolation.

4. **Implement CLI Tests**: Add end-to-end tests for CLI commands that use different models, ensuring proper argument handling and output validation.

5. **Add Error Scenario Coverage**: Create comprehensive error handling tests for network failures, corrupted caches, invalid models, and other edge cases.

6. **Performance Benchmarking**: Implement benchmarks to establish performance baselines for different model types and operations.

7. **Test Validation**: Ensure all tests pass, maintain fast execution times for unit tests, and properly isolate expensive integration tests with `#[ignore]` attributes.

The implementation will follow TurboProp's existing test architecture with fast unit tests (~8-10 seconds) for daily development and slower integration tests for comprehensive validation.

## Notes
- Some tests may require large model downloads and should be marked with `#[ignore]`
- Performance benchmarks help establish baselines for optimization
- Error tests ensure robust behavior in production
- Mock data may be needed for consistent testing without network dependencies